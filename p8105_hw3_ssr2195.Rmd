---
title: "Homework 3"
author: "Samina Rashiq"
output: github_document
---

## Problem 1

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)
```


```{r ny_noaa, include=FALSE}
data("ny_noaa")

# Calculate the number of unique weather stations
num_stations <- ny_noaa |>
  distinct(id) |>
  nrow()

# Calculate missing data percentages for relevant columns
missing_prcp <- ny_noaa |>
  summarize(missing = mean(is.na(prcp)) * 100) |>
  pull(missing)

missing_snow <- ny_noaa |>
  summarize(missing = mean(is.na(snow)) * 100) |>
  pull(missing)

# Correct column name 'snwd' for snow depth
missing_snwd <- ny_noaa |>
  summarize(missing = mean(is.na(snwd)) * 100) |>
  pull(missing)

missing_tmax <- ny_noaa |>
  summarize(missing = mean(is.na(tmax)) * 100) |>
  pull(missing)

missing_tmin <- ny_noaa |>
  summarize(missing = mean(is.na(tmin)) * 100) |>
  pull(missing)

# Get the total number of rows
total_rows <- nrow(ny_noaa)

```

This dataset is a subset of National Oceanic and Atmospheric Association (NOAA) weather data from January 1, 1981 to December 31, 2010. The data is from **`r num_stations` weather stations** in New York state and includes **`r format(total_rows, big.mark=",")` rows** and **7 columns**. 

Key variables include weather station ID (`id`), date of observation (`date`), precipitation in tenths of millimeters (`prcp`), snowfall in millimeters (`snow`), snow depth in millimeters (`sndw`), maximum temperature in tenths of degrees Celsius (`tmax`), and minimum temperature in tenths of degrees Celsius (`tmin`).

While each row contains a weather station ID and date, there is significant missing data across the remaining variables. Specifically, the columns for precipitation, snowfall, snow depth, maximum temperature, and minimum temperature are **`r round(missing_prcp, 2)`%**, **`r round(missing_snow, 2)`%**, **`r round(missing_snwd, 2)`%**, **`r round(missing_tmax, 2)`%**, and **`r round(missing_tmin, 2)`%** empty respectively. 

Missing data for precipitation, snowfall, and snow depth is likely due to days where those weather events did not occur and may not be a significant issue. However, the substantial amount of missing data for both maximum and minimum temperature poses a challenge, as nearly half of the rows lack this information.

```{r data_cleaning, echo=FALSE}
# Create new variables for year, month, and day
ny_noaa <- ny_noaa |>
  mutate(
    year = year(date),
    month = month(date),
    day = day(date),
    snow_mm = snow / 10          # Convert snowfall from tenths of mm to mm
  )

# Create a new variable for snow in millimeters
common_snowfall <- ny_noaa |>
  mutate(snow_mm = snow / 10) |>  # Convert snowfall to millimeters
  filter(!is.na(snow_mm)) |>      # Remove missing values
  count(snow_mm) |>               # Count occurrences of each snowfall value in mm
  arrange(desc(n)) |>             # Arrange in descending order
  rename("Snowfall (mm)" = snow_mm, "Frequency of Snowfall Value" = n)
```

#### Most commonly observed snowfall values in NY state
```{r snowfall_frequency_table, echo=FALSE}
# Display the table of the most common snowfall values
common_snowfall |> 
  head(10) |>  # Show the top 10 most common values
  knitr::kable()
```
0mm of snowfall is the most common value because snow generally only falls in certain months (November to March) and does not happen daily. This is followed by 2.5mm, 1.3mm, 5.1mm, and 7.6mm. These values are small and this makes sense because NY state is not very snowy compared to other places (e.g., Quebec, 10-30mm per day in these months). 

```{r find_max_temps, echo=FALSE}
# Load necessary libraries
library(dplyr)
library(ggplot2)

# Ensure 'tmax' is numeric throughout processing
ny_noaa <- ny_noaa |>
  mutate(tmax = as.numeric(tmax))

# Calculate average max temperatures for January for each station across years
avg_jan <- ny_noaa |>
  filter(month == 1) |>
  group_by(id) |>
  summarise(Avg_Max_Temp_Jan = mean(tmax / 10, na.rm = TRUE))  # Calculate mean, divide by 10

# Calculate average max temperatures for July for each station across years
avg_jul <- ny_noaa |>
  filter(month == 7) |>
  group_by(id) |>
  summarise(Avg_Max_Temp_Jul = mean(tmax / 10, na.rm = TRUE))  # Calculate mean, divide by 10

# Merge the two datasets on 'id' to get the average max temperatures for January and July
avg_max_temps <- inner_join(avg_jan, avg_jul, by = "id")

# Remove rows where there are missing maximum temperatures
avg_max_temps_clean <- avg_max_temps |>
  filter(!is.na(Avg_Max_Temp_Jan) & !is.na(Avg_Max_Temp_Jul))
```

#### Average max temperature in January and July for each station from 1981-2010
```{r histograms_max_temps, echo=FALSE}
# Calculate average max temperatures for January for each station across years
avg_jan <- ny_noaa |>
  filter(month == 1) |>
  group_by(id) |>
  summarise(Avg_Max_Temp_Jan = mean(as.numeric(tmax) / 10, na.rm = TRUE))  # Ensure tmax is numeric

# Histogram for January
ggplot(avg_max_temps_clean, aes(x = Avg_Max_Temp_Jan)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Distribution of Average Max Temperatures in January", x = "Average Max Temperature (째C)", y = "Frequency") +
  theme_minimal()

# Histogram for July
ggplot(avg_max_temps_clean, aes(x = Avg_Max_Temp_Jul)) +
  geom_histogram(binwidth = 1, fill = "red", color = "black") +
  labs(title = "Distribution of Average Max Temperatures in July", x = "Average Max Temperature (째C)", y = "Frequency") +
  theme_minimal()

```

The structure of the plots for average max temperatures for both January and July appear to follow a relatively symmetrical and normal looking distribution. Neither plot appears to have obvious outliers.


```{r}
# Convert tmin and tmax to numeric to avoid errors
ny_noaa <- ny_noaa |>
  mutate(
    tmin = as.numeric(tmin),
    tmax = as.numeric(tmax)
  )

# Panel 1: tmin (X) vs tmax (Y) using Hexbin plot for density
ggplot(ny_noaa, aes(x = tmin / 10, y = tmax / 10)) +
  geom_hex(bins = 50) +  # Hexbin plot to show density
  scale_fill_viridis_c() +
  labs(title = "tmax vs tmin (Hexbin Density Plot)", x = "Minimum Temperature (째C)", y = "Maximum Temperature (째C)") +
  theme_minimal()

# Filter snowfall values greater than 0 and less than 100
snow_filtered <- ny_noaa |>
  filter(snow > 0 & snow < 100) |>
  mutate(snow_mm = snow / 10)  

# Panel 2: Snowfall distribution by year (Boxplot)
ggplot(snow_filtered, aes(x = factor(year), y = snow_mm)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Distribution of Snowfall (0 < Snow < 100mm) by Year", x = "Year", y = "Snowfall (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 


```


## Problem 2

```{r import_tidy_merge}

#import demographics data
nhanes_covar <- read.csv("nhanes_covar.csv", header = FALSE, skip = 4)

colnames(nhanes_covar) <- nhanes_covar[1, ]
nhanes_covar <- nhanes_covar[-1, ]

#assign variable classes to demographics data
nhanes_covar$SEQN <- as.character(nhanes_covar$SEQN)

nhanes_covar$sex <- factor(
  nhanes_covar$sex,
  levels = c("1", "2"),
  labels = c("Male", "Female")
)

nhanes_covar$age <- as.numeric(nhanes_covar$age)

nhanes_covar$BMI <- as.numeric(nhanes_covar$BMI)

nhanes_covar$education <- factor(
  nhanes_covar$education,
  levels = c("1", "2", "3", "4"),
  labels = c("High School", "Bachelor's", "Master's", "PhD"),
  ordered = TRUE  # Specifies that it is ordinal data
)

#filter demographics data for missing values
nhanes_covar_filtered <- nhanes_covar %>%
  filter(age >= 21 & 
         !is.na(sex) & 
         !is.na(age) & 
         !is.na(BMI) & 
         !is.na(education))

#import accelerometer data
nhanes_accel <- read.csv("nhanes_accel.csv")

#assign variable classes to accelerometer data
nhanes_accel$SEQN <- as.character(nhanes_accel$SEQN)

nhanes_accel <- nhanes_accel %>%
  mutate(across(-SEQN, as.numeric))

#merge
nhanes_merged <- merge(nhanes_covar_filtered, nhanes_accel, by = "SEQN")

```

```{r education_table_graph}
library(knitr)
library(ggplot2)

#make sex/education table
sex_education_table <-
    table(nhanes_merged$education,
    nhanes_merged$sex)

kable(sex_education_table, caption = "Number of Men and Women in Each Education Category")

#make grouped bar plot of education grouped by sex
ggplot(nhanes_merged, aes(x = education, fill = sex)) +
  geom_bar(position = "dodge") +
  labs(title = "Age Distribution by Education and Sex",
       x = "Education Category",
       y = "Count",
       fill = "Sex") +
  theme_minimal()
```
The number of men and women appear to be relatively balanced across all four education categories. While gender differences do not appear to be an issue, there seems to be a higher proportion of participants at the master's level, which could bias the results.

```{r total_activity_scatter}
nhanes_merged$total_activity <- rowSums(nhanes_merged[, grep("^min", colnames(nhanes_merged))])

ggplot(nhanes_merged, aes(x = age, y = total_activity, color = sex)) +
  geom_point() +  
  geom_smooth(method = "lm", se = FALSE) + 
  facet_wrap(~education) + 
  labs(title = "Total Activity vs Age by Education Level and Sex",
       x = "Age",
       y = "Total Activity",
       color = "Sex") +  
  theme_minimal()
```
Total activity declines with age across all education levels. For those with a high school education, males start with higher activity but drop below females later in life. In contrast, females maintain higher activity levels for those with bachelor's and master's degrees. The decline in activity appears to slow as education levels increase.

```{r 24_hour_time_courses}

#gather minute-level data into a long format
nhanes_long <- nhanes_merged %>%
  pivot_longer(cols = starts_with("min"), 
               names_to = "minute", 
               values_to = "activity") %>%
  mutate(minute = as.numeric(gsub("min", "", minute)))

#calculate average activity per minute by education and sex
average_activity <- nhanes_long %>%
  group_by(education, sex, minute) %>%
  summarise(avg_activity = mean(activity, na.rm = TRUE))

#plot activity time courses
ggplot(average_activity, aes(x = minute, y = avg_activity, color = sex)) +
  geom_line() +  
  geom_smooth(se = FALSE, color = "black", size = 0.5) +
  facet_wrap(~education) +
  labs(title = "24-Hour Activity Time Course by Education Level and Sex",
       x = "Minute of Day",
       y = "Average Activity",
       color = "Gender") +
  theme_minimal() + 
  scale_x_continuous(breaks = seq(0, 1440, by = 720),
                     labels = c("12 AM", "12 PM", "12 AM"))
```

The graph suggests that those with a high school diploma as their highest education level are the most active overall for males and females around mid-day Those with bachelors and masters degrees seem to have a bimodal activity pattern around mid-day, while those with a high school diploma see a steady decrease in activity from noon onwards. The graph seems to suggest that rising and sleeping times are relatively similar accross education levels, based on where the peaks begin and end. In all three groups, females appear to be more active than males. Overall, it seems like gender is a smaller factor in determining activity throughout the day than is level of education. 

## Problem 3
```{r import_merge_citibike_dta}
file_names <- c("Jan 2024 Citi.csv",
                "Jan 2020 Citi.csv",
                "July 2020 Citi.csv",
                "July 2024 Citi.csv")

load_and_add_month <- function(file_name) {
  month_year <- gsub(" Citi.csv", "", file_name)
  df <- read_csv(file_name)
  df <- df %>% mutate(month = month_year)
  return(df)
}

citi_merged <- lapply(file_names, load_and_add_month) %>%
  bind_rows()

file_names <- c("Jan 2024 Citi.csv",
                "Jan 2020 Citi.csv",
                "July 2020 Citi.csv",
                "July 2024 Citi.csv")

load_and_add_month <- function(file_name) {
  month_year <- gsub(" Citi.csv", "", file_name)
  df <- read_csv(file_name)
  df <- df %>% mutate(month = month_year)
  return(df)
}

citi_merged <- lapply(file_names, load_and_add_month) %>%
  bind_rows()

num_rows <- nrow(citi_merged)
num_columns <- ncol(citi_merged)

incomplete_rides <- citi_merged %>%
  filter(is.na(start_station_name) | is.na(end_station_name)) %>%
  nrow()

mean_ride_time <- mean(citi_merged$duration, na.rm = TRUE)

common_start_station <- citi_merged %>%
  filter(!is.na(start_station_name)) %>%
  count(start_station_name, sort = TRUE) %>%
  top_n(1, wt = n) %>%
  pull(start_station_name)

common_end_station <- citi_merged %>%
  filter(!is.na(end_station_name)) %>%
  count(end_station_name, sort = TRUE) %>%
  top_n(1, wt = n) %>%
  pull(end_station_name)
```

The combined Citibike dataset has `r nrow(citi_merged)` rows and `r ncol(citi_merged)` columns. Key columns include ride ID, type of rideable vehicle, day of the week, duration of ride, start and end stations, and whether the rider was a member. There are `r citi_merged %>% filter(is.na(start_station_name) | is.na(end_station_name)) %>% nrow()` rides with incomplete data missing for start and/or end station. The mean ride time is `r round(mean(citi_merged$duration, na.rm = TRUE), 2)` minutes, and the most common start and end stations are `r citi_merged %>% filter(!is.na(start_station_name)) %>% count(start_station_name, sort = TRUE) %>% top_n(1, wt = n) %>% pull(start_station_name)` and `r citi_merged %>% filter(!is.na(end_station_name)) %>% count(end_station_name, sort = TRUE) %>% top_n(1, wt = n) %>% pull(end_station_name)` respectively.


```{r total_rides_table}
citi_merged <- citi_merged %>%
  mutate(month = factor(month, levels = c("Jan 2020", "July 2020", "Jan 2024", "July 2024")))

summary_table <- citi_merged %>%
  group_by(month, member_casual) %>%
  summarise(total_rides = n()) %>%
  spread(member_casual, total_rides) %>%
  arrange(month)

kable(summary_table, col.names = c("Month-Year", "Casual Rides", "Member Rides"), 
      caption = "Total Rides by Month-Year for Casual and Member Riders")
```

For every month-year, there were significantly more rides by members than rides from non-members. January 2020 had the lowest ridership for members and casual riders, and January in both years seems to have less overall riders than in July of both years. It is likely that warmer summer weather increases ridership.  

```{r most_pop_start_jul_2024}
popular_stations_july_2024 <- citi_merged %>%
  filter(month == "July 2024") %>%
  group_by(start_station_name) %>%
  summarise(total_rides = n()) %>%
  arrange(desc(total_rides)) %>%
  top_n(5, wt = total_rides)

kable(popular_stations_july_2024, col.names = c("Starting Station", "Total Rides"), 
      caption = "Top 5 Starting Stations in July 2024 by Number of Rides")
```


```{r median_duration}
library(ggplot2)
library(dplyr)
library(patchwork)

weekday_order <- c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")

median_duration_weekday <- citi_merged %>%
  group_by(weekdays) %>%
  summarise(median_duration = median(duration, na.rm = TRUE)) %>%
  mutate(weekdays = factor(weekdays, levels = weekday_order))

citi_merged <- citi_merged %>%
  mutate(month_only = ifelse(grepl("Jan", month), "January", "July"))

median_duration_month <- citi_merged %>%
  group_by(month_only) %>%
  summarise(median_duration = median(duration, na.rm = TRUE))

citi_merged <- citi_merged %>%
  mutate(year_only = ifelse(grepl("2020", month), "2020", "2024"))

median_duration_year <- citi_merged %>%
  group_by(year_only) %>%
  summarise(median_duration = median(duration, na.rm = TRUE))

y_axis_limit <- c(0, 13)  

p1 <- ggplot(median_duration_weekday, aes(x = weekdays, y = median_duration)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.6) +
  labs(x = "Day of the Week",
       y = "Median Ride Duration (minutes)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(y_axis_limit)

p2 <- ggplot(median_duration_month, aes(x = month_only, y = median_duration)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.6) +
  labs(x = "Month",
       y = "Median Ride Duration (minutes)") +
  theme_minimal() +
  ylim(y_axis_limit)

p3 <- ggplot(median_duration_year, aes(x = year_only, y = median_duration)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.6) +
  labs(x = "Year",
       y = "Median Ride Duration (minutes)") +
  theme_minimal() +
  ylim(y_axis_limit)

combined_plot <- (p1 | p2 | p3) +
  plot_annotation(title = "Comparison of Median Ride Duration by Weekday, Month, and Year")

print(combined_plot)
```

It appears that median ride length is longest on weekends.On weekdays, median ride length seems relatively stable, with Thursday having the highest median ride duration. Median ride duration is also ~5 minutes longer in July than January. During 2020, median ride duration was ~6 minutes longer than in 2024. 


```{r impact_month_status_bike}
data_2024 <- citi_merged %>%
  filter(year_only == "2024") 

ggplot(data_2024, aes(x = duration, fill = rideable_type, color = rideable_type)) +
  geom_density(alpha = 0.5) +  
  facet_wrap(~ interaction(month, member_casual)) +  
  labs(title = "Distribution of Ride Durations by Month, Membership, and Bike Type in 2024",
       x = "Ride Duration (minutes)",
       y = "Density",
       fill = "Bike Type",
       color = "Bike Type") +
  theme_minimal() +
  xlim(0, 60) 
```


In January 2024, casuals seemed to use e-bikes more often than they used classic bikes, especially for short rides around  minutes long. In January 2024, members seemed relatively evenly split between classic and e-bikes for most ride durations. 

In July 2024, we see a similar trend where casual riders tended to use e-bikes slightly more for rides less than 10 minutes long. Unlike for January 2024 members, July 2024 members used classic bikes slightly more for rides 1-10 minutes long. 

